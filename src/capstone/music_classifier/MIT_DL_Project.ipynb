{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6530,"status":"ok","timestamp":1706994711583,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"KKo4YkKdu0GR","outputId":"a775a8fd-85c5-4be8-d745-c7a298112fae"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time, copy\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as metrics\n","import torchvision.datasets\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from torch.utils.data import Subset\n","from torch.utils.data import DataLoader\n","from torch.nn.modules.flatten import Flatten\n","from torchvision.transforms import v2\n","\n","# device config (train our model on GPU if it is available which is much faster)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20592,"status":"ok","timestamp":1706994732169,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"LlKiecBj_ANF","outputId":"6d17c4c9-31f9-49de-bf72-027635e14f5f"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1706994732170,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"RGb3qVTqu72D"},"outputs":[],"source":["###\n","# Mood and Genre (not used at present for classification) are categorical variables. We will use the following encoding:\n","#\n","# Mood:\n","# 0 - Mellow\n","# 1 - Not Mellow\n","#\n","# Genre: (NOT USED)\n","# 0 - Jazz\n","# 1 - Jazz with Vocals\n","# 2 - Classical\n","# 3 - Pop\n","# 4 - Rock\n","# 5 - World\n","# 6 - Electronica\n","# 7 - Other\n","###\n","\n","class SongImageDataset(Dataset):\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        self.song_frame = pd.read_csv(csv_file, dtype={'image':str, 'genre':np.int64, 'mood':np.int64})\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.song_frame)\n","\n","    def __getitem__(self, index):\n","        if torch.is_tensor(index):\n","            index = index.tolist()\n","\n","        img_file = self.song_frame.iloc[index, 0]\n","        img_path = os.path.join(self.root_dir, img_file)\n","\n","        # if os.path.isfile(img_path):\n","        #     print(img_path)\n","        # else:\n","        #     print(\"File not found\")\n","        #     exit(1)\n","\n","        image = plt.imread(img_path)\n","        genre = self.song_frame.iloc[index, 1]\n","        mood = self.song_frame.iloc[index, 2]\n","\n","        return self.transform(image), mood, genre"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5072,"status":"ok","timestamp":1706994737234,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"Ja59vne8vBiQ","outputId":"3d99c13b-2e87-4bb8-85d5-956365d70ac0"},"outputs":[],"source":["# add transforms and instantiate the dataset\n","transform = v2.Compose([\n","    # v2.Resize(size=(300, 1200), antialias=True),\n","    # v2.ToDtype(torch.float32, scale=True),\n","    v2.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])])\n","\n","img_dataset = SongImageDataset(csv_file='/content/drive/MyDrive/MIT_DL_Project_Data/melspec/music_melspec_data.csv',\n","                           root_dir='/content/drive/MyDrive/MIT_DL_Project_Data/melspec',\n","                           transform=transform)\n","# print(len(dataset))\n","# print(dataset[0]['image'].shape)\n","# print(dataset[0]['filename'])\n","# print(dataset[0]['genre'])\n","# print(dataset[0]['mood'])\n","# print(dataset[0]['image'].dtype)\n","# plt.imshow(dataset[0]['image'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706994763910,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"S8zSf8yyJHLK","outputId":"e44b80a4-5435-4ac1-e740-6a5eb2e90a02"},"outputs":[],"source":["# dataset split\n","img_train, img_val = torch.utils.data.random_split(img_dataset, [int(len(img_dataset)*0.8), int(len(img_dataset)*0.2)])\n","print('train: ', len(img_train))\n","\n","img_val, img_test = torch.utils.data.random_split(img_val, [int(len(img_val)*0.5), int(len(img_val)*0.5)])\n","print('validation: ', len(img_val))\n","print('test: ', len(img_test))\n","\n","# dataloaders\n","batch_size = 32\n","dataloaders = {'train': DataLoader(img_train, batch_size=batch_size),\n","               'val': DataLoader(img_val, batch_size=batch_size),\n","               'test': DataLoader(img_test, batch_size=batch_size)}\n","\n","dataset_sizes = {'train': len(img_train),\n","                 'val': len(img_val),\n","                 'test': len(img_test)}\n","print(f'dataset_sizes = {dataset_sizes}')"]},{"cell_type":"markdown","metadata":{"id":"Rvjn7W38JhQl"},"source":["The image classifier class. Since the images are 1600x400 pixel size and contain a lot of detail, I added higher number of outchannels as the images were scaled down to a manageable size for linearizing. As the dataset was very small (410 elements), I chose to use a batch size of 16 (besides my validation and tesing size was just 41), so that it introduced a little bit of noise in the gradient estimation and thereby providing regularization."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1706994737235,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"mXx7NZTuJc9d"},"outputs":[],"source":["class CNNClassifier(nn.Module):\n","    def __init__(self, num_classes = 2, dropout = 0.25):\n","        super(CNNClassifier, self).__init__()\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # Convolutional layers\n","        self.conv0 = nn.Conv2d(in_channels=4, out_channels=32, kernel_size=3, padding=1)\n","        self.conv1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n","\n","        # Max-pooling layers\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Flattening layer\n","        self.flatten = nn.Flatten()\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(256 * 100 * 25, 512) # outchannels * (reduced_img_width * reduced_img_height)\n","        self.fc2 = nn.Linear(512, num_classes)\n","\n","        # Activation function\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        ####\n","        # 4 Convolution and 4 MaxPool layers with 2 fully connected layers.\n","        # We need to reduce the image size from 1600x400 100x25.\n","        ####\n","        x = self.relu(self.conv0(x))\n","        x = self.pool(x)\n","\n","        x = self.relu(self.conv1(x))\n","        x = self.pool(x)\n","\n","        x = self.relu(self.conv2(x))\n","        x = self.pool(x)\n","\n","        x = self.relu(self.conv3(x))\n","        x = self.pool(x)\n","\n","        # flatten the tensor 'x'\n","        # x = x.view(-1, 256 * 100 * 25)\n","        x = self.flatten(x)\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","\n","        # Final layer with softmax activation function.\n","        x = self.fc2(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"BShmgx4QZltS"},"source":["The training function is almost the same as the ones we have used in the past assignments, except that I added randomizing of the dataset split at any epoch iteration via a (epoch % randomize_epoch) param. It is a technique to introduce randomness into the training process and prevent overfitting. If the the dataset split was randomized every 10 epochs, the training curves for loss and accuracy looked very haphazard but eventually converged, whereas if the dataset was randomized every epoch, the curves looked less haphazard, but choppy and converged as well.\n","\n","The other small change made to the code was to add other_labels to the Tuple returned from the dataloaders when iterating over them. This was done, to see if I could train the CNN using the other_labels, which in this case is music Genre.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1706994737236,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"aceKPaZZLmoU"},"outputs":[],"source":["# training function\n","# From https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","def train_classification_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=25,  randomize_epoch = 5):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict()) # keep the best weights stored separately\n","    best_acc = 0.0\n","    best_epoch = 0\n","\n","    # Each epoch has a training, validation, and test phase\n","    phases = ['train', 'val', 'test']\n","\n","    # Keep track of how loss and accuracy evolves during training\n","    training_curves = {}\n","    for phase in phases:\n","        training_curves[phase+'_loss'] = []\n","        training_curves[phase+'_acc'] = []\n","\n","    for epoch in range(num_epochs):\n","        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        if epoch % randomize_epoch == 0:\n","            print('Randomize the dataset')\n","            img_train, img_val = torch.utils.data.random_split(img_dataset, [int(len(img_dataset)*0.8), int(len(img_dataset)*0.2)])\n","            img_val, img_test = torch.utils.data.random_split(img_val, [int(len(img_val)*0.5), int(len(img_val)*0.5)])\n","\n","            # We will create DataLoaders just like before with a batch size of 100\n","            dataloaders = {'train': DataLoader(img_train, batch_size=batch_size),\n","                        'val': DataLoader(img_val, batch_size=batch_size),\n","                        'test': DataLoader(img_test, batch_size=batch_size)}\n","\n","            dataset_sizes = {'train': len(img_train),\n","                            'val': len(img_val),\n","                            'test': len(img_test)}\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels, other_labels in dataloaders[phase]:\n","                # No need to flatten the inputs!\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, predictions = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + update weights only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(predictions == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            training_curves[phase+'_loss'].append(epoch_loss)\n","            training_curves[phase+'_acc'].append(epoch_acc)\n","\n","            print(f'{phase:5} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # deep copy the model if it's the best accuracy (bas\n","            if phase == 'val' and epoch_acc > best_acc:\n","              best_epoch = epoch\n","              best_acc = epoch_acc\n","              best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - since\n","    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f} at epoch {best_epoch}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, training_curves"]},{"cell_type":"markdown","metadata":{"id":"2bZv7JN-kvls"},"source":["The classification and plotting functions are pretty much the same as before with some minor changes to add other_labels to the Tuple and getting the class_labels from the labels tensor directly, instead of using a hardcoded class labels."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1706994737236,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"JR-gPJ9nMKFA"},"outputs":[],"source":["# classification function\n","def classify_predictions(model, device, dataloader):\n","    model.eval()   # Set model to evaluate mode\n","    all_labels = torch.tensor([]).to(device)\n","    all_scores = torch.tensor([]).to(device)\n","    all_preds = torch.tensor([]).to(device)\n","    for inputs, labels, other_labels in dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = torch.softmax(model(inputs), dim=1)\n","        _, preds = torch.max(outputs, 1)\n","        scores = outputs[:,1]\n","        all_labels = torch.cat((all_labels, labels), 0)\n","        all_scores = torch.cat((all_scores, scores), 0)\n","        all_preds = torch.cat((all_preds, preds), 0)\n","    return all_preds.detach().cpu(), all_labels.detach().cpu(), all_scores.detach().cpu()\n","\n","def plot_training_curves(training_curves,\n","                         phases=['train', 'val', 'test'],\n","                         metrics=['loss','acc']):\n","    epochs = list(range(len(training_curves['train_loss'])))\n","    for metric in metrics:\n","        plt.figure()\n","        plt.title(f'Training curves - {metric}')\n","        for phase in phases:\n","            key = phase+'_'+metric\n","            if key in training_curves:\n","                if metric == 'acc':\n","                    plt.plot(epochs, [item.detach().cpu() for item in training_curves[key]])\n","                else:\n","                    plt.plot(epochs, training_curves[key])\n","        plt.xlabel('epoch')\n","        plt.legend(labels=phases)\n","\n","def plot_cm(model, device, dataloaders, phase='test'):\n","    preds, labels, scores = classify_predictions(model, device, dataloaders[phase])\n","\n","    class_labels = labels.unique().tolist()\n","    print('class_labels: ', class_labels)\n","    print('preds: ', preds)\n","    print('labels: ', labels)\n","    cm = metrics.confusion_matrix(labels, preds)\n","    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","    ax = disp.plot().ax_\n","    ax.set_title('Confusion Matrix -- counts')"]},{"cell_type":"markdown","metadata":{"id":"z7xHze9FlVMP"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":644072,"status":"ok","timestamp":1706995416148,"user":{"displayName":"atin kothari","userId":"04810590409462990362"},"user_tz":480},"id":"ZsFWw-caMRRx","outputId":"ce325a00-1fe9-474b-be37-612630d97f02"},"outputs":[],"source":["learning_rate = 0.0001\n","num_epochs = 40\n","randomize_epoch = 1\n","\n","model = CNNClassifier(dropout = 0.5).to(device)\n","print(model)\n","\n","# loss and optimizer\n","criterion = nn.CrossEntropyLoss() # CrossEntropyLoss for classification!\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","\n","# Train the model. We also will store the results of training to visualize\n","model, training_curves = train_classification_model(model, dataloaders, dataset_sizes, criterion, optimizer,\n","                                                    scheduler, num_epochs=num_epochs,  randomize_epoch=randomize_epoch)\n","\n","plot_training_curves(training_curves, phases=['train', 'val', 'test'])\n","res = plot_cm(model, device, dataloaders, phase='test')\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNjc6lLNLQ0DORwhArZaTCt","gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
