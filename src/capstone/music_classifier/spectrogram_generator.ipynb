{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File to generate various visualizations for information retrieved from songs/music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from playsound import playsound\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, axis=0):\n",
    "    return minmax_scale(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the initial feature extraction from the audio file\n",
    "def mir(y, sr, hop_length=512, margin=8, bins_per_octave=12*3, n_bins=12*7*3, fmax = 8192):\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "\n",
    "    cqt = librosa.cqt(y=y, sr=sr, bins_per_octave=bins_per_octave, n_bins=n_bins)\n",
    "    stft = librosa.stft(y)\n",
    "    abs_stft_squared = np.abs(stft)**2\n",
    "\n",
    "    abs_cqt = np.abs(librosa.cqt(y=y, sr=sr, bins_per_octave=bins_per_octave, n_bins=n_bins))\n",
    "\n",
    "    # Get the harmonic component of the audio signal. \n",
    "    y_harmonic_only = librosa.effects.harmonic(y=y, margin=margin)\n",
    "\n",
    "    # Separate harmonic from percussive components  :\n",
    "    y_harmonic, y_percussive = librosa.decompose.hpss(stft)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=32)\n",
    "    melspec = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=hop_length, n_mels=32, fmax=fmax)\n",
    "\n",
    "    return melspec, mfcc, chroma_cqt, chroma_stft, cqt, stft, abs_stft_squared, abs_cqt, y_harmonic_only, y_harmonic, y_percussive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_melspec_and_mfcc(melspec, mfcc, filename, fig_width = 18, fig_height = 5, fmax = 8192, root_dir = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/'):\n",
    "    S_db = librosa.power_to_db(melspec, ref=np.max)\n",
    "\n",
    "    ###\n",
    "    # write out the mfcc and melspec images to files\n",
    "    ###\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    librosa.display.specshow(mfcc, fmax=fmax, cmap='magma')\n",
    "    plt.margins(0)\n",
    "    fpath = root_dir + 'mfcc_foo/mfcc_' + filename + '.png'\n",
    "    plt.savefig(fpath, transparent=False, bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    librosa.display.specshow(S_db, fmax=fmax, cmap='magma')\n",
    "    plt.margins(0)\n",
    "    fpath = root_dir + 'melspec_foo/melspec_' + filename + '.png'\n",
    "    plt.savefig(fpath, transparent=False, bbox_inches='tight', pad_inches=0, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrograms(music_csv, csv_outfile, root_dir = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/'):\n",
    "    for row in music_csv.itertuples(index=False):\n",
    "        filepath = row.file.replace(\"xyzyx\", \",\")\n",
    "        if filepath.startswith('DONE!'):\n",
    "            continue\n",
    "        song = filepath.split('/')[-1].replace(\"xyzyx\", \",\")\n",
    "        artist = filepath.split('/')[-3].replace(\"xyzyx\", \",\")\n",
    "        artist_and_song = artist + '__' + song\n",
    "        artist_and_song = artist_and_song.replace(\",\", \"_\")\n",
    "        genre = row.genre\n",
    "        mood = row.mood\n",
    "        print(filepath, artist_and_song, genre, mood)\n",
    "\n",
    "        # y (audio data) is of type numpy.ndarray\n",
    "        # sr (sample rate) is of type int \n",
    "        y, sr = librosa.load(filepath, offset=10.0, duration=30.0)\n",
    "        melspec, mfcc, chroma_cqt, chroma_stft, cqt, stft, abs_stft_squared, abs_cqt, y_harmonic_only, y_harmonic, y_percussive = mir(y, sr, hop_length=512, margin=8, bins_per_octave=12*3, n_bins=12*7*3)\n",
    "\n",
    "        write_melspec_and_mfcc(melspec, mfcc, artist_and_song, fig_width = 20.65, fig_height = 5.2, fmax = 10000, root_dir = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/')\n",
    "        csv_outfile.write('melspec_' + artist_and_song + '.png,' + str(genre) + ',' + str(mood) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/foo.csv'\n",
    "melspec_csv_file = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/music_melspec_data_foo.csv'\n",
    "music_csv = pd.read_csv(csv_file, dtype={'file':str, 'genre':np.int64, 'mood':np.int64})\n",
    "\n",
    "with open(melspec_csv_file, 'a') as outfile:\n",
    "    spectrograms(music_csv, outfile, root_dir = '/Users/sonatin/src/AI/MIT/Capstone/music-playlist/')\n",
    "    outfile.close()\n",
    "    print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
